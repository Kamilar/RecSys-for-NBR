{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfzLTcwaE9eM"
      },
      "outputs": [],
      "source": [
        "#from metrics import recall_k, ndcg_k, repeat_score_item, repeat_score_user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMEOu26D0gSC",
        "outputId": "6870c63d-548b-4750-9bc1-e8098b8e266a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awzhwLd2SxXm"
      },
      "outputs": [],
      "source": [
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3GwkQhrSxU1"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login(key='4da15e357372a40c1c71a28c87306f19bf380d80')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaQpzVq_WT9n"
      },
      "outputs": [],
      "source": [
        "def wandb_start(config, run_name):\n",
        "    wandb.init(project=\"NBR_instacart\", config=config)\n",
        "    wandb.run.name = run_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PwKoqUXfFI6"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C65AzIwS0gSD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import json\n",
        "import itertools\n",
        "import sys\n",
        "from scipy.sparse import csr_matrix, vstack\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9pNJa4R0gSv"
      },
      "outputs": [],
      "source": [
        "basket_count_min = 3\n",
        "min_item_count = 5\n",
        "history_len = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycHZRfMdHXn4"
      },
      "outputs": [],
      "source": [
        "path_train = '/content/drive/MyDrive/insta_baskets_30k/train_baskets_30k.csv'  # для файлов что выше сделались\n",
        "path_val = '/content/drive/MyDrive/insta_baskets_30k/valid_baskets_30k.csv'\n",
        "path_test = '/content/drive/MyDrive/insta_baskets_30k/test_baskets_30k.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PreDataset(path_train,path_val, path_test, dataset=dataset_name, history_len=history_len,basket_count_min=3, min_item_count = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kfJ1DXHUiLR",
        "outputId": "92e70c4f-eeb1-418a-87c7-4c59a32c39ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of test users: 28749\n",
            "items: 43728\n",
            "filtered items: 30002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Было сделано 3 модификации модели, которые описаны ниже"
      ],
      "metadata": {
        "id": "TAJrqi4GQwR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modification 1\n",
        "\n",
        "### Creating a multi-hot vector for each user about user's all items consuming followed some linear blocks, which will replace user_embedding"
      ],
      "metadata": {
        "id": "lkWW-3tLLweH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwVZo9iR0gSx"
      },
      "outputs": [],
      "source": [
        "multihot_dict = {}\n",
        "for user_id, items_list in zip(train_baskets.groupby(['user_id'])['item_id'].apply(list).reset_index()['user_id'],\n",
        "                               train_baskets.groupby(['user_id'])['item_id'].apply(list).reset_index()['item_id']):\n",
        "    l1 = sorted(list(set([dataset.item_id_mapper[item] for item in items_list if item in dataset.item_id_mapper])))\n",
        "    multihot_dict[dataset.user_id_mapper[user_id]] = [1 if i in l1 else 0 for i in np.array(list(dataset.id_item_mapper.keys()))]\n",
        "    print(len(list(multihot_dict.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgR73qh8bzyD",
        "outputId": "41d3595a-6f78-4166-cfce-8319862a950e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzzFkFxaMMj7"
      },
      "outputs": [],
      "source": [
        "history_len=20\n",
        "item_embed_size=128\n",
        "user_embed_size=32\n",
        "\n",
        "h1 = 128\n",
        "h2 = 128\n",
        "h3 = 128\n",
        "h4 = 128\n",
        "h5 = 128\n",
        "dataset_name = 'du'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk1QMees0gS3",
        "outputId": "301be903-75a9-4052-912f-759cc1880af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of test users: 2483\n",
            "items: 91764\n",
            "filtered items: 36963\n"
          ]
        }
      ],
      "source": [
        "dataset = PreDataset(path_train,path_val, path_test, dataset=dataset_name, history_len=history_len,basket_count_min=3, min_item_count = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsmgdNZh0gS3"
      },
      "outputs": [],
      "source": [
        "train_baskets = pd.read_csv(path_train)\n",
        "test_baskets = pd.read_csv(path_test)\n",
        "valid_baskets = pd.read_csv(path_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FXbhBxCdfiR",
        "outputId": "5dbc1137-a4e0-40e0-a7c1-68f66bbc4936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.PreDataset at 0x7fe19a938460>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfPXXdRt0gS4",
        "outputId": "a320a125-b171-4841-a305-dd7e0085cd1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((157182, 10), (158033, 10), (4594693, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "test_baskets.shape, valid_baskets.shape, train_baskets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYUec4ql0gS4",
        "outputId": "0e7bd8f6-e5ba-4570-82e5-6127e6cf456a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data allready in use\n"
          ]
        }
      ],
      "source": [
        "batch_size = 4096\n",
        "\n",
        "train_dataset = RCNDataset(dataset, mode='train')\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = RCNDataset(dataset, mode='valid')\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = RCNDataset(dataset, mode='test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P21yv3KT3H5",
        "outputId": "5b83b593-1bde-4c06-9ad1-d4e96c8c4ca5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50176675, 643538, 658898)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Z3Ke2QH9RT",
        "outputId": "72378492-3e64-414a-eac2-2ddb0f924673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25733472, 929152, 933822)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block part with linear layer for running on multi-hot vector of each user"
      ],
      "metadata": {
        "id": "XTwO7267ONlo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71pxQINMeCn4"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(dim_in, dim_out)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        #self.norm = nn.BatchNorm2d(dim_out)\n",
        "        self.norm = nn.LayerNorm(dim_out, elementwise_affine = False)\n",
        "        #self.dropout = nn.Dropout(0.2)\n",
        "        self.act = nn.Tanh()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.act(self.norm(self.dropout(self.dense(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eoLJUqQ0gS5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class ReCaNet(nn.Module):\n",
        "    def __init__(self, num_items, item_embed_size, num_users, user_embed_size, history_len, h1, h2, h3, h4, h5):\n",
        "        super(ReCaNet, self).__init__()\n",
        "        self.num_items = num_items\n",
        "        self.item_embed_size = item_embed_size\n",
        "        self.num_users = num_users\n",
        "        self.user_embed_size = user_embed_size\n",
        "        self.history_len = history_len\n",
        "        self.h1 = h1\n",
        "        self.h2 = h2\n",
        "        self.h3 = h3\n",
        "        self.h4 = h4\n",
        "        self.h5 = h5\n",
        "\n",
        "        self.item_embedding = nn.Embedding(self.num_items, self.item_embed_size)\n",
        "        self.user_embedding = nn.Embedding(self.num_users, self.user_embed_size)\n",
        "        \n",
        "        #self.fc1 = nn.Linear(self.item_embed_size + 36963, self.h1)\n",
        "            #self.item_embed_size + self.user_embed_size, self.h1)\n",
        "        self.fc1 = nn.Linear(self.item_embed_size + + self.user_embed_size, self.h1)\n",
        "        self.fc2 = nn.Linear(self.h1+1, self.h2)\n",
        "        self.lstm1 = nn.LSTM(self.h2, self.h3, batch_first=True, num_layers=2)\n",
        "        #self.lstm2 = nn.LSTM(self.h3, self.h4, batch_first=True)\n",
        "        self.fc5 = nn.Linear(self.h4, self.h5)\n",
        "        self.fc6 = nn.Linear(self.h4, self.h5)\n",
        "        self.fc7 = nn.Linear(self.h5, 1)\n",
        "        self.layers = nn.Sequential(\n",
        "               Block(36963, 2048), \n",
        "               Block(2048, 512), \n",
        "               Block(512, 128)\n",
        "        )\n",
        "        # self.encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=16, batch_first=True)\n",
        "        # self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=8)\n",
        "\n",
        "    def forward(self, input1, input2, input4):\n",
        "        x1 = self.item_embedding(input1.to(torch.int64))\n",
        "        x1 = x1.view(-1, self.item_embed_size) #1x128\n",
        "       \n",
        "        #x2 = self.user_embedding(input2.to(torch.int64))\n",
        "        x2 = torch.tensor(np.array([multihot_dict[i.item()] for i in input2.to(torch.int64)])).long().to(torch.float32).to(device)\n",
        "        x2 = x2.view(-1, 36963)\n",
        "                     #self.user_embed_size) #1x32\n",
        "        #x2 = x2.view(-1, self.user_embed_size)\n",
        "        x2 = self.layers(x2)\n",
        "        # 1x5\n",
        "        x4 = input4 # 1x5\n",
        "        x4 = x4.unsqueeze(2)\n",
        "        \n",
        "        conc1 = torch.cat((x1, x2), axis=1)\n",
        "        x11 = F.relu(self.fc1(conc1)) # 1*128\n",
        "\n",
        "        x12 = x11.unsqueeze(1).repeat(1, self.history_len, 1)\n",
        "        \n",
        "        conc2 = torch.cat((x12, x4), 2)#.transpose(-2,-1)\n",
        "        x14 = F.relu(self.fc2(conc2))\n",
        "        #valid_his = (input4 > 0).long()\n",
        "\n",
        "        x21, (hx, cx) = self.lstm1(x14)             #Прежняя часть с LSTM\n",
        "        x22 = hx[1]                                 #Прежняя часть с LSTM\n",
        "       \n",
        "        #x22 = self.transformer_encoder(x14).mean(dim=1)\n",
        "        x = F.relu(self.fc5(x22))\n",
        "        x = F.relu(self.fc6(x))\n",
        "      \n",
        "        output = self.fc7(x).view(-1) \n",
        "        output = torch.sigmoid(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCizQlat_2gO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "762kh71g0gS6"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_new = ReCaNet(num_items=dataset.num_items, item_embed_size=item_embed_size, num_users=dataset.num_users, \n",
        "                user_embed_size=user_embed_size, history_len = history_len, h1 = h1,h2 = h2, h3 = h3,\n",
        "                h4 = h4, h5 = h5).to(device)\n",
        "\n",
        "#path_best = '/kaggle/input/weights/epoch_5_recanet_model_dunnhumby.pth'\n",
        "#model_new.load_state_dict(torch.load(path_best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BraqZCLqG8Ww"
      },
      "outputs": [],
      "source": [
        "wandb_start(config, 'recanet_instacart')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7UMh8K-gHaC",
        "outputId": "0b0e8fd6-7dde-4249-d9d8-d49e6ec451a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.watch(model_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MlgVbG10gS7"
      },
      "outputs": [],
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model_new\n",
        "\n",
        "import torch.nn.functional as F # 22min\n",
        "test_baskets = pd.read_csv(path_test) \n",
        "#path_test\n",
        "#pd.read_csv(path_test)\n",
        "user_test_baskets_df = test_baskets.groupby('user_id')['item_id'].apply(list).reset_index()\n",
        "user_test_baskets_dict = dict(zip( user_test_baskets_df['user_id'],user_test_baskets_df['item_id']))\n",
        "\n",
        "user_predictions = predict(best_model, test_loader)\n",
        "final_users = set(dataset.test_users).intersection(set(list(user_test_baskets_dict.keys())))\n",
        "print('predictions ready',len(user_predictions))\n",
        "print('number of final test users:',len(final_users))\n",
        "for k in [5,10,20,'B']:\n",
        "    print(k)\n",
        "    recall_scores = {}\n",
        "    ndcg_scores = {}\n",
        "    #zero = 0\n",
        "    for user in final_users:\n",
        "\n",
        "        top_items = []\n",
        "        if user in user_predictions:\n",
        "            top_items = user_predictions[user]\n",
        "        else:\n",
        "            zero+=1\n",
        "\n",
        "        if k == 'B':\n",
        "            recall_scores[user] = recall_k(user_test_baskets_dict[user],top_items,len(user_test_baskets_dict[user]))\n",
        "            ndcg_scores[user] = ndcg_k(user_test_baskets_dict[user],top_items,len(user_test_baskets_dict[user]))\n",
        "        else:\n",
        "            recall_scores[user] = recall_k(user_test_baskets_dict[user],top_items,k)\n",
        "            ndcg_scores[user] = ndcg_k(user_test_baskets_dict[user],top_items,k)\n",
        "    #print(zero)\n",
        "    print('recall:',np.mean(list(recall_scores.values())))\n",
        "    print('ndcg:',np.mean(list(ndcg_scores.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "6fd39e2cfb604b4abf62211bbdae98e6",
            "b51ece3ff9fd44ec821489e7e9719abd",
            "4a742a66edb546d5af212ad0f93d82aa",
            "2822b5d26e70484bb28844206d5c0a59",
            "b1e3d36673e64822907b64131020503b",
            "5c7ddec5baa944e8a119b9e632c9641c",
            "7eb931dfd4494f4dba33606da7789c1b",
            "ac1e5a02459640949919517d8351116c",
            "0fe00eddeb194fa6b6236dd66e1a061d",
            "d671f097f61843008fabc5adfc775894",
            "1d4365d77b7c43a894f5cd64a6ec5931"
          ]
        },
        "id": "MramNgioVHdi",
        "outputId": "8824eb1d-6c4d-4b14-ec76-b2d00bf45c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/228 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fd39e2cfb604b4abf62211bbdae98e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions ready 28749\n",
            "number of final test users: 14366\n",
            "5\n",
            "recall: 0.253004308674264\n",
            "ndcg: 0.4227910320972693\n",
            "10\n",
            "recall: 0.3581563042608666\n",
            "ndcg: 0.3515862669553688\n",
            "20\n",
            "recall: 0.46451642003850374\n",
            "ndcg: 0.2726473842689201\n",
            "B\n",
            "recall: 0.329087256964059\n",
            "ndcg: 0.37177391142322236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modification 2\n",
        "\n",
        "### Replacing 2 sequential LSTM layers with the TransformerEncoder with 4 layers and 4 heads, with embedding dimension of 128"
      ],
      "metadata": {
        "id": "JBEEx8cZO0Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "self.lstm1 = nn.LSTM(self.h2, self.h3, batch_first=True, num_layers=2)\n",
        "\n",
        "   x21, (hx, cx) = self.lstm1(x14)             \n",
        "   x22 = hx[1]     --------------->>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "   --------------->>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "self.encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=4, batch_first=True)\n",
        "self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
        "x22 = self.transformer_encoder(x14).mean(dim=1)"
      ],
      "metadata": {
        "id": "ZWBK7eOcPa1I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ8U-s9KgvFx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N52mzDmjPF4R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class ReCaNet(nn.Module):\n",
        "    def __init__(self, num_items, item_embed_size, num_users, user_embed_size, history_len, h1, h2, h3, h4, h5):\n",
        "        super(ReCaNet, self).__init__()\n",
        "        self.num_items = num_items\n",
        "        self.item_embed_size = item_embed_size\n",
        "        self.num_users = num_users\n",
        "        self.user_embed_size = user_embed_size\n",
        "        self.history_len = history_len\n",
        "        self.h1 = h1\n",
        "        self.h2 = h2\n",
        "        self.h3 = h3\n",
        "        self.h4 = h4\n",
        "        self.h5 = h5\n",
        "\n",
        "        self.item_embedding = nn.Embedding(self.num_items, self.item_embed_size)\n",
        "        self.user_embedding = nn.Embedding(self.num_users, self.user_embed_size)\n",
        "        \n",
        "        #self.fc1 = nn.Linear(self.item_embed_size + 36963, self.h1)\n",
        "            #self.item_embed_size + self.user_embed_size, self.h1)\n",
        "        self.fc1 = nn.Linear(self.item_embed_size + + self.user_embed_size, self.h1)\n",
        "        self.fc2 = nn.Linear(self.h1+1, self.h2)\n",
        "        self.lstm1 = nn.LSTM(self.h2, self.h3, batch_first=True, num_layers=2)\n",
        "        #self.lstm2 = nn.LSTM(self.h3, self.h4, batch_first=True)\n",
        "        self.fc5 = nn.Linear(self.h4, self.h5)\n",
        "        self.fc6 = nn.Linear(self.h4, self.h5)\n",
        "        self.fc7 = nn.Linear(self.h5, 1)\n",
        "        # self.layers = nn.Sequential(\n",
        "        #        Block(36963, 2048), \n",
        "        #        Block(2048, 512), \n",
        "        #        Block(512, 128)\n",
        "        # )\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=4, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
        "\n",
        "    def forward(self, input1, input2, input4):\n",
        "        x1 = self.item_embedding(input1.to(torch.int64))\n",
        "        x1 = x1.view(-1, self.item_embed_size) #1x128\n",
        "       \n",
        "        x2 = self.user_embedding(input2.to(torch.int64))\n",
        "        #x2 = torch.tensor(np.array([multihot_dict[i.item()] for i in input2.to(torch.int64)])).long().to(torch.float32).to(device)\n",
        "        #x2 = x2.view(-1, 36963)\n",
        "                     #self.user_embed_size) #1x32\n",
        "        x2 = x2.view(-1, self.user_embed_size)\n",
        "        #x2 = self.layers(x2)\n",
        "        # 1x5\n",
        "        x4 = input4 # 1x5\n",
        "        x4 = x4.unsqueeze(2)\n",
        "        \n",
        "        conc1 = torch.cat((x1, x2), axis=1)\n",
        "        x11 = F.relu(self.fc1(conc1)) # 1*128\n",
        "\n",
        "        x12 = x11.unsqueeze(1).repeat(1, self.history_len, 1)\n",
        "        \n",
        "        conc2 = torch.cat((x12, x4), 2)#.transpose(-2,-1)\n",
        "        x14 = F.relu(self.fc2(conc2))\n",
        "        #valid_his = (input4 > 0).long()\n",
        "\n",
        "        # x21, (hx, cx) = self.lstm1(x14)             #Прежняя часть с LSTM\n",
        "        # x22 = hx[1]                                 #Прежняя часть с LSTM\n",
        "       \n",
        "        x22 = self.transformer_encoder(x14).mean(dim=1)\n",
        "        x = F.relu(self.fc5(x22))\n",
        "        x = F.relu(self.fc6(x))\n",
        "      \n",
        "        output = self.fc7(x).view(-1) \n",
        "        output = torch.sigmoid(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modification 3\n",
        "\n",
        "### Predicting additional new explore items for user from global top-1000 popular items in all dataset"
      ],
      "metadata": {
        "id": "SYqPvCOuP5Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "top_popular = self.train_baskets.item_id.value_counts().index.tolist()[:1000]\n",
        "\n",
        "\n",
        "                for explore_item in top_popular:\n",
        "                    if dataset.item_id_mapper[explore_item] not in train_items:\n",
        "                        train_users.append(dataset.user_id_mapper[user])\n",
        "                        train_items.append(dataset.item_id_mapper[explore_item])\n",
        "                        #train_history.append(real_input_history[-dataset.history_len:])\n",
        "                        train_history2.append([0 for i in range(20)])\n",
        "                        #print(item, basket_items_dict[label_basket])\n",
        "                        train_labels.append(float(explore_item in basket_items_dict[label_basket]))"
      ],
      "metadata": {
        "id": "P7ta_K7uQUjc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGvMSdwVQJQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyJ6MGnJQJNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing dataset for torch.dataset class\n",
        "class PreDataset():\n",
        "    def __init__(self, path_train,path_val, path_test, dataset, history_len, basket_count_min=0,\\\n",
        "                                                         min_item_count = 0):\n",
        "        self.basket_count_min = basket_count_min\n",
        "        self.min_item_count = min_item_count\n",
        "        self.history_len = history_len\n",
        "        \n",
        "        self.train_baskets = pd.read_csv(path_train)\n",
        "        self.valid_baskets = pd.read_csv(path_val)\n",
        "        self.test_baskets = pd.read_csv(path_test)\n",
        "        \n",
        "        basket_per_user = self.train_baskets[['user_id','basket_id']].drop_duplicates() \\\n",
        "            .groupby('user_id').agg({'basket_id':'count'}).reset_index()\n",
        "        self.test_users = basket_per_user[basket_per_user['basket_id'] >= self.basket_count_min]['user_id'].tolist()\n",
        "    \n",
        "        print(\"number of test users:\", len(self.test_users))\n",
        "        \n",
        "        self.model_name = 'data/dunnhumby_cj/'+dataset+ '_recanet'\n",
        "        self.dataset = dataset\n",
        "        self.all_items = self.train_baskets[['item_id']].drop_duplicates()['item_id'].tolist()\n",
        "        self.all_users = self.train_baskets[['user_id']].drop_duplicates()['user_id'].tolist()\n",
        "        self.num_items = len(self.all_items) +1\n",
        "        self.num_users = len(self.all_users) +1\n",
        "\n",
        "        print(\"items:\", self.num_items)\n",
        "        item_counts = self.train_baskets.groupby(['item_id']).size().to_frame(name = 'item_count').reset_index()\n",
        "        item_counts = item_counts[item_counts['item_count']>= min_item_count]\n",
        "        item_counts_dict = dict(zip(item_counts['item_id'], item_counts['item_count']))\n",
        "        print(\"filtered items:\", len(item_counts_dict))\n",
        "        self.num_items = len(item_counts_dict) +1\n",
        "        self.item_id_mapper = {} \n",
        "        self.id_item_mapper = {} \n",
        "        self.user_id_mapper = {} \n",
        "        self.id_user_mapper = {} \n",
        "\n",
        "        counter = 0\n",
        "        for i in range(len(self.all_items)):\n",
        "            if self.all_items[i] in item_counts_dict:\n",
        "                self.item_id_mapper[self.all_items[i]] = counter+1\n",
        "                self.id_item_mapper[counter+1] = self.all_items[i]\n",
        "                counter+=1\n",
        "        for i in range(len(self.all_users)):\n",
        "            self.user_id_mapper[self.all_users[i]] = i+1\n",
        "            self.id_user_mapper[i+1] = self.all_users[i]\n",
        "            \n",
        "            \n",
        "    def create_train_data(self):\n",
        "        if os.path.isfile('/content/drive/MyDrive/tafeng_data/20_test_history22.npy'):\n",
        "        #if os.path.isfile('/kaggle/input/npy-files/dunnhumby_cj_recanet_20_test_history2.npy'):\n",
        "        #if os.path.isfile(self.model_name +'_' + str(self.history_len) + '_train_users.npy'):\n",
        "            print('Data allready in use')\n",
        "            train_users = np.load('/content/drive/MyDrive/tafeng_data/20' + '_train_users.npy')\n",
        "            train_items = np.load('/content/drive/MyDrive/tafeng_data/20' + '_train_items.npy')\n",
        "            #train_history = np.load(self.model_name +'_' + str(self.history_len) + '_train_history.npy')\n",
        "            train_history2 = np.load('/content/drive/MyDrive/tafeng_data/20' + '_train_history2.npy')\n",
        "            train_labels = np.load('/content/drive/MyDrive/tafeng_data/20'+ '_train_labels.npy')\n",
        "            return train_items,train_users, train_history2, train_labels\n",
        "        row_counts = 0 \n",
        "        basket_items = self.train_baskets.groupby(['basket_id'])['item_id'].apply(list).reset_index()\n",
        "        basket_items_dict = dict(zip(basket_items['basket_id'],basket_items['item_id']))\n",
        "        basket_items_dict['null'] = [] \n",
        "\n",
        "        user_baskets = self.train_baskets[['user_id','date','basket_id']].drop_duplicates().\\\n",
        "            sort_values(['user_id','date'],ascending=True).groupby(['user_id'])['basket_id'].apply(list).reset_index()\n",
        "\n",
        "        user_baskets_dict = dict(zip(user_baskets['user_id'], user_baskets['basket_id']))\n",
        "        top_popular = self.train_baskets.item_id.value_counts().index.tolist()[:1000]\n",
        "\n",
        "\n",
        "        train_users = []\n",
        "        train_items = []\n",
        "        train_history = []\n",
        "        train_history2 = []\n",
        "        train_labels = []\n",
        "        print('num users:', len(self.test_users))\n",
        "\n",
        "        for c,user in tqdm(enumerate(self.test_users)):\n",
        "            if c % 1000 ==1:\n",
        "                print(c , 'user passed')\n",
        "\n",
        "            baskets = user_baskets_dict[user]\n",
        "            item_seq = {}\n",
        "            for i, basket in enumerate(baskets):\n",
        "                for item in basket_items_dict[basket]:\n",
        "                    if item not in self.item_id_mapper:\n",
        "                        continue\n",
        "                    if item not in item_seq:\n",
        "                        item_seq[item] = []\n",
        "                    item_seq[item].append(i)\n",
        "\n",
        "\n",
        "            for i in range(max(0,len(baskets)-50), len(baskets)):\n",
        "                label_basket = baskets[i]\n",
        "                all_history_baskets = baskets[:i]\n",
        "                items = []\n",
        "                for basket in all_history_baskets:\n",
        "                    for item in basket_items_dict[basket]:\n",
        "                        items.append(item)\n",
        "                items = list(set(items))\n",
        "                for item in items:\n",
        "                    if item not in self.item_id_mapper:\n",
        "                        continue\n",
        "                    index = np.argmax(np.array(item_seq[item])>=i)\n",
        "                    if np.max(np.array(item_seq[item])) < i:\n",
        "                        index = len(item_seq[item])\n",
        "                    input_history = item_seq[item][:index].copy()\n",
        "                    if len(input_history) ==0:\n",
        "                        continue\n",
        "                    if len(input_history) ==1 and input_history[0]==-1:\n",
        "                        continue\n",
        "                    while len(input_history) < self.history_len:\n",
        "                        input_history.insert(0,-1)\n",
        "                    real_input_history = []\n",
        "                    for x in input_history:\n",
        "                        if x == -1:\n",
        "                            real_input_history.append(0)\n",
        "                        else:\n",
        "                            real_input_history.append(i-x)\n",
        "                    real_input_history2 = []\n",
        "                    for j,x in enumerate(input_history[:-1]):\n",
        "                        if x == -1:\n",
        "                            real_input_history2.append(0)\n",
        "                        else:\n",
        "                            real_input_history2.append(input_history[j+1]-input_history[j])\n",
        "                    real_input_history2.append(i-input_history[-1])\n",
        "                    train_users.append(self.user_id_mapper[user])\n",
        "                    train_items.append(self.item_id_mapper[item])\n",
        "                    train_history.append(real_input_history[-self.history_len:])\n",
        "                    train_history2.append(real_input_history2[-self.history_len:])\n",
        "                    #print(item, basket_items_dict[label_basket])\n",
        "                    train_labels.append(float(item in basket_items_dict[label_basket]))\n",
        "                for explore_item in top_popular:\n",
        "                    if dataset.item_id_mapper[explore_item] not in train_items:\n",
        "                        train_users.append(dataset.user_id_mapper[user])\n",
        "                        train_items.append(dataset.item_id_mapper[explore_item])\n",
        "                        #train_history.append(real_input_history[-dataset.history_len:])\n",
        "                        train_history2.append([0 for i in range(20)])\n",
        "                        #print(item, basket_items_dict[label_basket])\n",
        "                        train_labels.append(float(explore_item in basket_items_dict[label_basket]))\n",
        "\n",
        "                    row_counts +=1\n",
        "            print(row_counts)\n",
        "\n",
        "        train_items = np.array(train_items)\n",
        "        train_users = np.array(train_users)\n",
        "        #train_history = np.array(train_history)\n",
        "        train_history2 = np.array(train_history2)\n",
        "        train_labels = np.array(train_labels)\n",
        "        random_indices = np.random.choice(range(len(train_items)), len(train_items),replace=False)\n",
        "        train_items = train_items[random_indices]\n",
        "        train_users = train_users[random_indices]\n",
        "        #train_history = train_history[random_indices]\n",
        "        train_history2 = train_history2[random_indices]\n",
        "        train_labels = train_labels[random_indices]        \n",
        "\n",
        "        np.save('/content/drive/MyDrive/tafeng_data/' + str(self.history_len) + '_train_items.npy',train_items)\n",
        "        np.save('/content/drive/MyDrive/tafeng_data/' + str(self.history_len) + '_train_users.npy',train_users)\n",
        "      \n",
        "        np.save('/content/drive/MyDrive/tafeng_data/' + str(self.history_len) + '_train_history2.npy',train_history2)\n",
        "        np.save('/content/drive/MyDrive/tafeng_data/' + str(self.history_len) + '_train_labels.npy',train_labels)\n",
        "\n",
        "        return train_items,train_users, train_history2 , train_labels\n",
        "    \n",
        "    \n",
        "    def create_test_data(self,test_data='test'):\n",
        "        if os.path.isfile('/content/drive/MyDrive/tafeng_data/20_test_history22.npy'):\n",
        "        #if os.path.isfile('/kaggle/input/npy-files/dunnhumby_cj_recanet_20_test_history2.npy'):\n",
        "        #if os.path.isfile(self.model_name +'_' + str(self.history_len)+ '_'+test_data+'_users.npy'):\n",
        "            test_users = np.load('/content/drive/MyDrive/tafeng_data/20' + '_'+test_data+'_users.npy')\n",
        "            test_items = np.load('/content/drive/MyDrive/tafeng_data/20' + '_'+test_data+'_items.npy')\n",
        "            #test_history = np.load(self.model_name +'_' + str(self.history_len) + '_'+test_data+'_history.npy')\n",
        "            test_history2 = np.load('/content/drive/MyDrive/tafeng_data/20' + '_'+test_data+'_history2.npy')\n",
        "            test_labels = np.load('/content/drive/MyDrive/tafeng_data/20' + '_'+test_data+'_labels.npy')\n",
        "            return test_items,test_users,test_history2, test_labels\n",
        "\n",
        "        train_basket_items = self.train_baskets.groupby(['basket_id'])['item_id'].apply(list).reset_index()\n",
        "        train_basket_items_dict = dict(zip(train_basket_items['basket_id'],train_basket_items['item_id']))\n",
        "\n",
        "        train_user_baskets = self.train_baskets[['user_id','date','basket_id']].drop_duplicates(). \\\n",
        "            sort_values(['user_id','date'],ascending=True).groupby(['user_id'])['basket_id'].apply(list).reset_index()\n",
        "        train_user_baskets_dict = dict(zip(train_user_baskets['user_id'],train_user_baskets['basket_id']))\n",
        "\n",
        "        train_user_items = self.train_baskets[['user_id','item_id']].drop_duplicates().groupby(['user_id'])['item_id'] \\\n",
        "            .apply(list).reset_index()\n",
        "        train_user_items_dict = dict(zip(train_user_items['user_id'],train_user_items['item_id']))\n",
        "\n",
        "        test_user_items = None\n",
        "        if test_data == 'test':\n",
        "            test_user_items = self.test_baskets.groupby(['user_id'])['item_id'].apply(list).reset_index()\n",
        "        else:\n",
        "            test_user_items = self.valid_baskets.groupby(['user_id'])['item_id'].apply(list).reset_index()\n",
        "        test_user_items_dict = dict(zip(test_user_items['user_id'],test_user_items['item_id']))\n",
        "\n",
        "        top_popular = self.train_baskets.item_id.value_counts().index.tolist()[:1000]\n",
        "\n",
        "        test_users = []\n",
        "        test_items = []\n",
        "        test_history = []\n",
        "        test_history2 = []\n",
        "        test_labels = []\n",
        "\n",
        "        train_basket_items_dict['null'] = []\n",
        "        for c,user in tqdm(enumerate(test_user_items_dict)):\n",
        "            if user not in train_user_baskets_dict:\n",
        "                continue\n",
        "            if c % 100 ==1:\n",
        "                print(c , 'user passed')\n",
        "                #break\n",
        "\n",
        "            baskets = train_user_baskets_dict[user]\n",
        "            item_seq = {}\n",
        "            for i, basket in enumerate(baskets):\n",
        "                for item in train_basket_items_dict[basket]:\n",
        "                    if item not in self.item_id_mapper:\n",
        "                        continue\n",
        "                    if item not in item_seq:\n",
        "                        item_seq[item] = []\n",
        "                    item_seq[item].append(i)\n",
        "\n",
        "\n",
        "            label_items = test_user_items_dict[user]\n",
        "\n",
        "            items = list(set(train_user_items_dict[user]))\n",
        "\n",
        "            #print(len(history_baskets))\n",
        "            for item in items:#train_user_items_dict[user]:\n",
        "                if item not in self.item_id_mapper:\n",
        "                    continue\n",
        "                input_history = item_seq[item][-self.history_len:]\n",
        "                if len(input_history) ==0:\n",
        "                    continue\n",
        "                if len(input_history) ==1 and input_history[0]==-1:\n",
        "                    continue\n",
        "                while len(input_history) < self.history_len:\n",
        "                    input_history.insert(0,-1)\n",
        "\n",
        "                real_input_history2 = []\n",
        "                for j,x in enumerate(input_history[:-1]):\n",
        "                    if x == -1:\n",
        "                        real_input_history2.append(0)\n",
        "                    else:\n",
        "                        real_input_history2.append(input_history[j+1]-input_history[j])\n",
        "                real_input_history2.append(len(baskets)-input_history[-1])\n",
        "                test_users.append(self.user_id_mapper[user])\n",
        "                test_items.append(self.item_id_mapper[item])\n",
        "                #test_history.append(real_input_history)\n",
        "                test_history2.append(real_input_history2)\n",
        "                test_labels.append(float(item in label_items))\n",
        "            for explore_item in top_popular:\n",
        "                if dataset.item_id_mapper[explore_item] not in test_items:\n",
        "                    test_users.append(self.user_id_mapper[user])\n",
        "                    test_items.append(self.item_id_mapper[explore_item])\n",
        "                    test_history2.append([0 for i in range(20)])\n",
        "                    #print(item, basket_items_dict[label_basket])\n",
        "                    test_labels.append(float(explore_item in label_items))\n",
        "\n",
        "        test_items = np.array(test_items)\n",
        "        test_users = np.array(test_users)\n",
        "        #test_history = np.array(test_history)\n",
        "        test_history2 = np.array(test_history2)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "        np.save('/content/drive/MyDrive/tafeng_data/20' + '_'+test_data+'_items.npy',test_items)\n",
        "        np.save('/content/drive/MyDrive/tafeng_data/'+ str(self.history_len) + '_'+test_data+'_users.npy',test_users)\n",
        "       \n",
        "        np.save('/content/drive/MyDrive/tafeng_data/'+ str(self.history_len) + '_'+test_data+'_history2.npy',test_history2)\n",
        "        #sparse.save_npz('Downloads/dunnhumby/'+ str(self.history_len) + '_'+test_data+'_history2.npz', test_history2)\n",
        "        np.save('/content/drive/MyDrive/tafeng_data/'+ str(self.history_len) + '_'+test_data+'_labels.npy',test_labels)\n",
        "\n",
        "        return test_items, test_users, test_history2, test_labels"
      ],
      "metadata": {
        "_uuid": "01017f53-70e4-45ae-943e-3ca4cb2e6425",
        "_cell_guid": "ca884e1a-cd46-457d-a25b-aa37af3fc6d4",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-02-13T18:58:55.621364Z",
          "iopub.execute_input": "2023-02-13T18:58:55.621784Z",
          "iopub.status.idle": "2023-02-13T18:58:55.669364Z",
          "shell.execute_reply.started": "2023-02-13T18:58:55.621745Z",
          "shell.execute_reply": "2023-02-13T18:58:55.668376Z"
        },
        "trusted": true,
        "id": "LTPePJUDarGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fd39e2cfb604b4abf62211bbdae98e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b51ece3ff9fd44ec821489e7e9719abd",
              "IPY_MODEL_4a742a66edb546d5af212ad0f93d82aa",
              "IPY_MODEL_2822b5d26e70484bb28844206d5c0a59"
            ],
            "layout": "IPY_MODEL_b1e3d36673e64822907b64131020503b"
          }
        },
        "b51ece3ff9fd44ec821489e7e9719abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7ddec5baa944e8a119b9e632c9641c",
            "placeholder": "​",
            "style": "IPY_MODEL_7eb931dfd4494f4dba33606da7789c1b",
            "value": "100%"
          }
        },
        "4a742a66edb546d5af212ad0f93d82aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1e5a02459640949919517d8351116c",
            "max": 228,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fe00eddeb194fa6b6236dd66e1a061d",
            "value": 228
          }
        },
        "2822b5d26e70484bb28844206d5c0a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d671f097f61843008fabc5adfc775894",
            "placeholder": "​",
            "style": "IPY_MODEL_1d4365d77b7c43a894f5cd64a6ec5931",
            "value": " 228/228 [00:26&lt;00:00,  8.89it/s]"
          }
        },
        "b1e3d36673e64822907b64131020503b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7ddec5baa944e8a119b9e632c9641c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb931dfd4494f4dba33606da7789c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac1e5a02459640949919517d8351116c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe00eddeb194fa6b6236dd66e1a061d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d671f097f61843008fabc5adfc775894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4365d77b7c43a894f5cd64a6ec5931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}